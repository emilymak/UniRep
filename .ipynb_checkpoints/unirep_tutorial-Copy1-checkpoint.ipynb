{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "USE_FULL_1900_DIM_MODEL = False # if True use 1900 dimensional model, else use 64 dimensional one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set seeds\n",
    "tf.set_random_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "if USE_FULL_1900_DIM_MODEL:\n",
    "    # Sync relevant weight files\n",
    "    !aws s3 sync --no-sign-request --quiet s3://unirep-public/1900_weights/ 1900_weights/\n",
    "    \n",
    "    # Import the mLSTM babbler model\n",
    "    from unirep import babbler1900 as babbler\n",
    "    \n",
    "    # Where model weights are stored.\n",
    "    MODEL_WEIGHT_PATH = \"./1900_weights\"\n",
    "    \n",
    "else:\n",
    "    # Sync relevant weight files\n",
    "    !aws s3 sync --no-sign-request --quiet s3://unirep-public/64_weights/ 64_weights/\n",
    "    \n",
    "    # Import the mLSTM babbler model\n",
    "    from unirep import babbler64 as babbler\n",
    "    \n",
    "    # Where model weights are stored.\n",
    "    MODEL_WEIGHT_PATH = \"./64_weights\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "batch_size = 50\n",
    "b = babbler(batch_size=batch_size, model_path=MODEL_WEIGHT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Before you can train your model, \n",
    "sequences = []\n",
    "with open(\"clinical_vh_1.txt\", \"r\") as source:\n",
    "    with open(\"formatted.txt\", \"w\") as destination:\n",
    "        for i,seq in enumerate(source):\n",
    "            seq = seq.strip()\n",
    "            sequences.append(seq)\n",
    "            if b.is_valid_seq(seq) and len(seq) < 275: \n",
    "                formatted = \",\".join(map(str,b.format_seq(seq)))\n",
    "                destination.write(formatted)\n",
    "                destination.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-abae7d084eab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mnum1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnum1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mavg_hidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal_hidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal_cell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhs_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_rep_hs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequences\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0maverage_hidden_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mavg_hidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mfinal_hidden_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal_hidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "## \n",
    "average_hidden_list = []\n",
    "final_hidden_list = []\n",
    "hs_list = []\n",
    "final_cell_list = []\n",
    "\n",
    "\n",
    "num2 = range(0, 50)\n",
    "x = 0\n",
    "y = 50\n",
    "for i in num2:\n",
    "    num1 = range(x, y)\n",
    "    for j in num1:\n",
    "        avg_hidden, final_hidden, final_cell, hs_out = (b.get_rep_hs(sequences[j]))\n",
    "        average_hidden_list.append(avg_hidden)\n",
    "        final_hidden_list.append(final_hidden)\n",
    "        final_cell_list.append(final_cell)\n",
    "        hs_list.append(hs_out)\n",
    "        print('rep')\n",
    "    x = x + 50\n",
    "    y = y + 50\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             0         1         2         3         4         5         6   \\\n",
      "0     -0.165004  0.367741  0.358379 -0.652705  0.310745  0.112354  0.319343   \n",
      "1     -0.156224  0.020769 -0.005827 -0.946178 -0.175482  0.024309  0.109565   \n",
      "2     -0.076103  0.039707 -0.068597 -0.982010 -0.074966 -0.034950  0.068059   \n",
      "3     -0.058311  0.053986 -0.086645 -0.987298 -0.051170 -0.053258  0.027245   \n",
      "4     -0.003677  0.076352 -0.109282 -0.989626 -0.047260 -0.053738  0.027420   \n",
      "5     -0.038077  0.097799 -0.118403 -0.985669 -0.050498 -0.049629  0.037225   \n",
      "6      0.025612  0.064812 -0.113066 -0.984256 -0.059101 -0.051365  0.012105   \n",
      "7      0.049025  0.082313 -0.087995 -0.990922 -0.041432 -0.112213  0.029521   \n",
      "8      0.006583  0.135147 -0.078896 -0.990121 -0.015207 -0.122814  0.061241   \n",
      "9      0.008933  0.127565 -0.079991 -0.987132 -0.015113 -0.152265  0.025057   \n",
      "10     0.077980  0.103989 -0.058407 -0.984953 -0.021431 -0.128419  0.045190   \n",
      "11     0.026909  0.202782 -0.059125 -0.989396 -0.018550 -0.105592  0.042051   \n",
      "12     0.035936  0.159157 -0.088357 -0.969360 -0.026968 -0.056122  0.024937   \n",
      "13     0.059801  0.093132 -0.055557 -0.975596  0.002670 -0.008614  0.013640   \n",
      "14     0.062550  0.186707 -0.051769 -0.991475 -0.006423 -0.028718 -0.005721   \n",
      "15    -0.011214  0.167544 -0.043082 -0.991248 -0.011145 -0.035595  0.034426   \n",
      "16     0.058632  0.181080 -0.040065 -0.987976  0.017790 -0.069905  0.001385   \n",
      "17     0.029970  0.136943 -0.033349 -0.990374  0.005956 -0.082746  0.020479   \n",
      "18     0.000441  0.139913 -0.038506 -0.990033 -0.004634 -0.071803  0.016742   \n",
      "19     0.010915  0.160127 -0.046023 -0.979786 -0.002303 -0.025715 -0.015243   \n",
      "20     0.000773  0.222996 -0.049428 -0.987504  0.004572 -0.033628  0.006430   \n",
      "21     0.025222  0.186978 -0.068745 -0.972566  0.009812 -0.064642  0.029696   \n",
      "22     0.014874  0.136089 -0.071880 -0.985632 -0.014120 -0.041224 -0.008277   \n",
      "23     0.013732  0.130824 -0.094137 -0.940037  0.016129 -0.021758  0.006848   \n",
      "24     0.047726  0.229312 -0.075778 -0.970450  0.047901 -0.024321  0.058626   \n",
      "25     0.005446  0.134665 -0.081405 -0.963261  0.027115 -0.037166 -0.022676   \n",
      "26     0.001609  0.202963 -0.070327 -0.969039  0.027783 -0.023668  0.017781   \n",
      "27     0.024343  0.183205 -0.061413 -0.969468  0.032074 -0.061346 -0.002046   \n",
      "28     0.069994  0.201369 -0.031687 -0.977257  0.034662 -0.097255  0.057331   \n",
      "29     0.004937  0.149035 -0.105595 -0.969461  0.000466 -0.061555  0.007493   \n",
      "...         ...       ...       ...       ...       ...       ...       ...   \n",
      "77121  0.057757  0.313220 -0.107712 -0.958126 -0.028880 -0.379841  0.081215   \n",
      "77122  0.024308  0.245126 -0.249077 -0.928406 -0.041690 -0.365971  0.057387   \n",
      "77123  0.003686  0.219405 -0.223382 -0.896888 -0.005607 -0.367043  0.088812   \n",
      "77124 -0.002589  0.128048 -0.212422 -0.827847  0.007881 -0.359032  0.091624   \n",
      "77125  0.028787  0.109072 -0.241928 -0.895031 -0.022435 -0.297111  0.015787   \n",
      "77126  0.004249  0.092007 -0.275305 -0.776753 -0.027631 -0.210476  0.031024   \n",
      "77127  0.004020  0.099367 -0.240281 -0.849051 -0.027115 -0.232320  0.024861   \n",
      "77128  0.050190  0.168267 -0.245609 -0.819597 -0.017825 -0.294517  0.157888   \n",
      "77129  0.079809  0.102141 -0.165470 -0.884947 -0.017478 -0.265004  0.054350   \n",
      "77130  0.079927  0.251406 -0.160762 -0.962407 -0.032909 -0.264855  0.099984   \n",
      "77131  0.034207  0.267261 -0.146011 -0.978340 -0.033775 -0.319418  0.077336   \n",
      "77132  0.023766  0.222113 -0.115594 -0.970061 -0.011429 -0.338036  0.144035   \n",
      "77133  0.021024  0.195245 -0.134224 -0.964549  0.007653 -0.355428  0.117194   \n",
      "77134  0.002263  0.172188 -0.129754 -0.944066  0.034865 -0.423774  0.061438   \n",
      "77135  0.014458  0.155250 -0.108760 -0.972408  0.025328 -0.416507  0.043160   \n",
      "77136  0.015815  0.202854 -0.186053 -0.948996 -0.002560 -0.319151  0.007601   \n",
      "77137  0.004361  0.234638 -0.172943 -0.960633  0.001760 -0.361950  0.049281   \n",
      "77138 -0.010563  0.155811 -0.212664 -0.954313 -0.001274 -0.338234  0.013811   \n",
      "77139  0.013487  0.185648 -0.201081 -0.910879 -0.007335 -0.291271  0.108191   \n",
      "77140  0.058350  0.115598 -0.236231 -0.843827 -0.015447 -0.240232  0.028286   \n",
      "77141  0.013739  0.145354 -0.206311 -0.812101 -0.015261 -0.286168  0.023469   \n",
      "77142  0.060186  0.104737 -0.199516 -0.857921 -0.019641 -0.291436  0.027195   \n",
      "77143  0.042911  0.167086 -0.139373 -0.923355 -0.020612 -0.312365  0.072912   \n",
      "77144  0.108372  0.227619 -0.137534 -0.975003 -0.022789 -0.414845  0.123145   \n",
      "77145  0.037756  0.213830 -0.189044 -0.980367 -0.045492 -0.368331  0.081452   \n",
      "77146  0.035431  0.287514 -0.197517 -0.970354 -0.038718 -0.309057  0.094828   \n",
      "77147  0.039422  0.247933 -0.217159 -0.936247 -0.040791 -0.307017  0.145782   \n",
      "77148 -0.012341  0.169637 -0.361329 -0.866087 -0.057960 -0.291764  0.053670   \n",
      "77149  0.031982  0.178620 -0.386519 -0.649750 -0.039964 -0.291843  0.093331   \n",
      "77150  0.053674  0.108289 -0.289884 -0.647223 -0.029540 -0.338060  0.056864   \n",
      "\n",
      "             7         8         9     ...           54        55        56  \\\n",
      "0      0.479474  0.566543  0.441343    ...     0.537194  0.512816  0.240133   \n",
      "1      0.108014  0.036832 -0.132778    ...     0.043055  0.063621 -0.021644   \n",
      "2      0.092981  0.163093 -0.054431    ...     0.037193  0.030412  0.071537   \n",
      "3      0.115106  0.120097 -0.164142    ...     0.046072  0.025641  0.055651   \n",
      "4      0.155599  0.163205 -0.143081    ...     0.053135  0.030944  0.110881   \n",
      "5      0.159635  0.174306 -0.124355    ...     0.062251  0.020353  0.117015   \n",
      "6      0.186465  0.157787 -0.161483    ...     0.067689  0.023296  0.123832   \n",
      "7      0.176079  0.200251 -0.158324    ...     0.054021  0.026638  0.132952   \n",
      "8      0.169030  0.212899 -0.221204    ...     0.060218  0.005316  0.015762   \n",
      "9      0.210119  0.217192 -0.265375    ...     0.067813  0.014017  0.088167   \n",
      "10     0.250093  0.124040 -0.227202    ...     0.056659 -0.003319  0.066461   \n",
      "11     0.147191  0.169260 -0.306931    ...     0.050413 -0.009246  0.021361   \n",
      "12     0.315876  0.157280 -0.265005    ...     0.095552 -0.015065  0.081112   \n",
      "13     0.342136  0.193036 -0.279929    ...     0.112255 -0.001664  0.103319   \n",
      "14     0.285693  0.127764 -0.365324    ...     0.137205 -0.009927  0.159071   \n",
      "15     0.264832  0.129591 -0.366905    ...     0.098436 -0.019926 -0.001309   \n",
      "16     0.367824  0.119783 -0.407532    ...     0.111354 -0.023082  0.160573   \n",
      "17     0.259494  0.185185 -0.361639    ...     0.065524 -0.013946  0.166405   \n",
      "18     0.197030  0.176720 -0.402051    ...     0.083203 -0.010517  0.140349   \n",
      "19     0.345719  0.141291 -0.340079    ...     0.137557 -0.016372  0.160160   \n",
      "20     0.172252  0.167280 -0.481209    ...     0.121422 -0.028451  0.109289   \n",
      "21     0.276378  0.180244 -0.314023    ...     0.123142 -0.016370  0.149385   \n",
      "22     0.157362  0.315546 -0.393191    ...     0.145586 -0.003677  0.190528   \n",
      "23     0.373720  0.179608 -0.306049    ...     0.224222 -0.006104  0.096121   \n",
      "24     0.239332  0.259099 -0.542170    ...     0.275786 -0.003259  0.178869   \n",
      "25     0.257398  0.226703 -0.383032    ...     0.207569 -0.003979  0.124776   \n",
      "26     0.292308  0.284314 -0.498784    ...     0.154011 -0.048385  0.111783   \n",
      "27     0.300263  0.239137 -0.439333    ...     0.154252 -0.031844  0.067342   \n",
      "28     0.324730  0.223094 -0.373027    ...     0.104587 -0.035718  0.134271   \n",
      "29     0.141127  0.217844 -0.522398    ...     0.150605 -0.023745  0.075959   \n",
      "...         ...       ...       ...    ...          ...       ...       ...   \n",
      "77121  0.152600  0.359555 -0.456455    ...     0.144058 -0.002833  0.053258   \n",
      "77122  0.135664  0.370380 -0.433176    ...     0.208426  0.012377  0.086577   \n",
      "77123  0.203862  0.356524 -0.319850    ...     0.171742  0.024824  0.058370   \n",
      "77124  0.201038  0.364146 -0.325174    ...     0.206567  0.028299  0.060728   \n",
      "77125  0.111316  0.290282 -0.420732    ...     0.202988  0.025662  0.103234   \n",
      "77126  0.209664  0.256558 -0.262010    ...     0.213739  0.018190  0.112646   \n",
      "77127  0.166382  0.357117 -0.400256    ...     0.171581  0.022794  0.149723   \n",
      "77128  0.272700  0.386895 -0.497294    ...     0.165776  0.023784  0.186364   \n",
      "77129  0.176673  0.281212 -0.508725    ...     0.142135 -0.000782  0.093330   \n",
      "77130  0.136393  0.334315 -0.616737    ...     0.128729 -0.012912  0.056734   \n",
      "77131  0.195020  0.372411 -0.375921    ...     0.172013  0.000419  0.066151   \n",
      "77132  0.219308  0.402467 -0.358234    ...     0.129383  0.006940  0.047457   \n",
      "77133  0.178916  0.421027 -0.621175    ...     0.197735 -0.016467  0.017487   \n",
      "77134  0.257787  0.403887 -0.553131    ...     0.218071 -0.025549  0.007766   \n",
      "77135  0.197759  0.357199 -0.526813    ...     0.134636 -0.007330  0.015670   \n",
      "77136  0.213505  0.393143 -0.515413    ...     0.235549  0.013597  0.084271   \n",
      "77137  0.255653  0.357660 -0.385748    ...     0.197282  0.027667  0.040741   \n",
      "77138  0.150712  0.343521 -0.493895    ...     0.219324  0.034864  0.049444   \n",
      "77139  0.302300  0.337192 -0.353692    ...     0.168477  0.034385  0.109791   \n",
      "77140  0.169491  0.253613 -0.545853    ...     0.278945  0.014058  0.054994   \n",
      "77141  0.252331  0.268839 -0.491641    ...     0.278685  0.012395  0.059557   \n",
      "77142  0.276452  0.218539 -0.491912    ...     0.280887  0.015238  0.048929   \n",
      "77143  0.217297  0.307685 -0.671232    ...     0.233800 -0.022345  0.029648   \n",
      "77144  0.257558  0.236516 -0.610799    ...     0.238804 -0.027384  0.041608   \n",
      "77145  0.109654  0.283935 -0.699923    ...     0.239742 -0.017991 -0.003962   \n",
      "77146  0.190947  0.259292 -0.413172    ...     0.261196  0.032928  0.035991   \n",
      "77147  0.149016  0.331417 -0.460168    ...     0.249332  0.038534  0.078234   \n",
      "77148  0.084667  0.259690 -0.634510    ...     0.348019  0.021734  0.034296   \n",
      "77149  0.249310  0.347220 -0.345470    ...     0.371717  0.043484  0.136631   \n",
      "77150  0.174108  0.431114 -0.543478    ...     0.243858  0.032338  0.155885   \n",
      "\n",
      "             57        58        59        60        61        62        63  \n",
      "0      0.487939  0.511597  0.349602 -0.145424 -0.455004  0.441083  0.015762  \n",
      "1     -0.076822 -0.164030  0.893134  0.008492  0.016379  0.301379  0.005142  \n",
      "2     -0.032667 -0.108770  0.888038 -0.030944 -0.022160  0.497383 -0.016388  \n",
      "3     -0.030964 -0.047055  0.861368 -0.051400 -0.038630  0.666427 -0.020759  \n",
      "4     -0.036768 -0.044220  0.816845 -0.046780 -0.055321  0.660834 -0.026113  \n",
      "5     -0.064195 -0.058449  0.819727 -0.053925 -0.038737  0.674398 -0.017432  \n",
      "6     -0.048263 -0.037435  0.778645 -0.060062 -0.016980  0.652568 -0.019643  \n",
      "7     -0.030426 -0.038942  0.705063 -0.075229 -0.065626  0.657501 -0.067168  \n",
      "8      0.035158 -0.037259  0.774125 -0.105098 -0.029515  0.639903 -0.045360  \n",
      "9     -0.037739 -0.030386  0.660063 -0.127395 -0.085441  0.572246 -0.085825  \n",
      "10    -0.103659 -0.002936  0.692104 -0.162095 -0.067467  0.600933 -0.004912  \n",
      "11    -0.133821  0.000229  0.687867 -0.150174 -0.082718  0.557086 -0.009580  \n",
      "12    -0.200778 -0.011217  0.575031 -0.178972 -0.070315  0.479866 -0.006530  \n",
      "13    -0.151392  0.019952  0.523976 -0.228020 -0.025012  0.502675  0.033962  \n",
      "14    -0.185315  0.005921  0.560682 -0.257437 -0.066823  0.499618  0.007613  \n",
      "15    -0.078992 -0.023821  0.601956 -0.188844 -0.052808  0.455927 -0.025289  \n",
      "16    -0.142497  0.000680  0.599247 -0.224612 -0.105688  0.476499 -0.039322  \n",
      "17    -0.130926 -0.018574  0.462415 -0.183796 -0.049165  0.495711 -0.056372  \n",
      "18    -0.164547 -0.006038  0.537005 -0.174843 -0.052648  0.508777  0.009857  \n",
      "19    -0.267873 -0.016887  0.544652 -0.217414 -0.061035  0.447292  0.025399  \n",
      "20    -0.165588 -0.018657  0.525783 -0.214575 -0.087700  0.454747  0.008836  \n",
      "21    -0.232572 -0.008371  0.402627 -0.172029 -0.072603  0.491755 -0.008352  \n",
      "22    -0.105586 -0.042746  0.269446 -0.100759 -0.051021  0.420040 -0.000352  \n",
      "23    -0.236962 -0.018610  0.305138 -0.166258 -0.052423  0.425097  0.001632  \n",
      "24    -0.078124 -0.025090  0.424588 -0.124569 -0.086726  0.550138 -0.004036  \n",
      "25    -0.213625 -0.050935  0.253519 -0.096010 -0.053096  0.425840 -0.046857  \n",
      "26    -0.032066 -0.038446  0.323970 -0.106320 -0.014013  0.464584  0.013379  \n",
      "27    -0.090702 -0.104696  0.236527 -0.101135 -0.053850  0.430836 -0.020581  \n",
      "28    -0.162372 -0.061815  0.293373 -0.121171 -0.079581  0.534640 -0.018843  \n",
      "29    -0.181059 -0.043288  0.351088 -0.104985 -0.059686  0.470484  0.007404  \n",
      "...         ...       ...       ...       ...       ...       ...       ...  \n",
      "77121  0.089380 -0.061953  0.239051 -0.150808 -0.047401  0.600738 -0.027619  \n",
      "77122  0.049556 -0.059887  0.188366 -0.123237 -0.058325  0.527283 -0.026912  \n",
      "77123 -0.060330 -0.012551  0.169913 -0.146885 -0.070402  0.555614 -0.075869  \n",
      "77124  0.016835 -0.031812  0.126459 -0.133470 -0.048245  0.460822 -0.086910  \n",
      "77125 -0.029516 -0.049021  0.138626 -0.121512 -0.050275  0.454583 -0.025749  \n",
      "77126 -0.106098 -0.025692  0.132506 -0.148309 -0.030042  0.379658 -0.053748  \n",
      "77127 -0.071538 -0.017737  0.143015 -0.153983 -0.023975  0.465596 -0.040510  \n",
      "77128 -0.026865  0.017751  0.141427 -0.161128  0.008910  0.509560 -0.093299  \n",
      "77129 -0.104334 -0.021521  0.137232 -0.226669 -0.049996  0.468764 -0.043117  \n",
      "77130  0.062690 -0.056272  0.221987 -0.186266 -0.032888  0.427065 -0.032570  \n",
      "77131  0.019177 -0.082401  0.181979 -0.128344 -0.087312  0.400840 -0.036330  \n",
      "77132 -0.009886 -0.036381  0.131547 -0.163986 -0.051054  0.479123 -0.095335  \n",
      "77133  0.134821 -0.033609  0.164514 -0.150050 -0.026139  0.499308 -0.053551  \n",
      "77134  0.084606 -0.070711  0.125382 -0.121588 -0.023423  0.432174 -0.105523  \n",
      "77135 -0.018448 -0.062387  0.117833 -0.120021 -0.081843  0.465821 -0.100717  \n",
      "77136  0.053309 -0.094173  0.143671 -0.102961 -0.077635  0.386424 -0.067998  \n",
      "77137  0.040220 -0.091091  0.142642 -0.114996 -0.061557  0.460946 -0.097399  \n",
      "77138  0.042313 -0.072126  0.102991 -0.104390 -0.059466  0.447833 -0.059741  \n",
      "77139  0.009530 -0.019565  0.108894 -0.090708 -0.045380  0.513080 -0.072273  \n",
      "77140  0.019408 -0.047688  0.152762 -0.115992 -0.056049  0.527525 -0.007616  \n",
      "77141  0.046082 -0.043463  0.172662 -0.090928 -0.021090  0.477884 -0.027152  \n",
      "77142 -0.000079 -0.053111  0.107319 -0.104489 -0.064099  0.430064 -0.037717  \n",
      "77143  0.086479 -0.034811  0.199487 -0.098581 -0.023413  0.522942 -0.022722  \n",
      "77144  0.026915 -0.021592  0.218002 -0.149480 -0.129306  0.517333 -0.038456  \n",
      "77145  0.061761 -0.067422  0.211937 -0.113610 -0.102517  0.448463 -0.036868  \n",
      "77146  0.018893 -0.044308  0.228223 -0.100154 -0.107489  0.481378 -0.051078  \n",
      "77147 -0.022647 -0.009506  0.182638 -0.106184 -0.089125  0.553757 -0.056032  \n",
      "77148 -0.038600 -0.023062  0.180235 -0.115604 -0.092119  0.476187 -0.035942  \n",
      "77149 -0.079077  0.030265  0.166064 -0.102428 -0.062380  0.549351 -0.071043  \n",
      "77150 -0.061532  0.000610  0.080685 -0.111205 -0.042610  0.530894 -0.099283  \n",
      "\n",
      "[77151 rows x 64 columns]\n"
     ]
    }
   ],
   "source": [
    "average_hidden_pd = pd.DataFrame(np.row_stack(average_hidden_list))\n",
    "final_hidden_pd = pd.DataFrame(np.row_stack(final_hidden_list))\n",
    "hidden_state = pd.DataFrame(np.row_stack(hs_list))\n",
    "print(hidden_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "average_hidden_pd.to_csv(\"clinical_vh_1_reps.csv\")\n",
    "final_hidden_pd.to_csv(\"clinical_vh_1_finalhidden.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "save_loc = \"C:\\\\Users\\\\makow\\\\Documents\\\\GitHub\\\\UniRep\\\\Datasets\"\n",
    "data_name = 'clinical_vh_1'\n",
    "file_append = '.pickle'\n",
    "\n",
    "\n",
    "fn = save_loc + data_name + 'avg_hidden' + file_append\n",
    "with open(fn, 'wb') as f:\n",
    "    pickle.dump(average_hidden_list, f)\n",
    "\n",
    "fn = save_loc + data_name + 'final_hidden' + file_append\n",
    "with open(fn, 'wb') as f:\n",
    "    pickle.dump(final_hidden_list, f)\n",
    "\n",
    "fn = save_loc + data_name + 'final_cell' + file_append\n",
    "with open(fn, 'wb') as f:\n",
    "    pickle.dump(final_cell_list, f)\n",
    "   \n",
    "fn = save_loc + data_name + 'hidden_state' + file_append\n",
    "with open(fn, 'wb') as f:\n",
    "    pickle.dump(hs_list, f)\n",
    "   \n",
    "fn = save_loc + data_name + 'all_output_hs' + file_append\n",
    "with open(fn, 'wb') as f:\n",
    "    pickle.dump([average_hidden_list, final_hidden_list, final_cell_list, hs_list], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
