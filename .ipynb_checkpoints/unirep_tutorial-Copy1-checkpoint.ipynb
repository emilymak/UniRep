{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "USE_FULL_1900_DIM_MODEL = False # if True use 1900 dimensional model, else use 64 dimensional one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set seeds\n",
    "tf.set_random_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "if USE_FULL_1900_DIM_MODEL:\n",
    "    # Sync relevant weight files\n",
    "    !aws s3 sync --no-sign-request --quiet s3://unirep-public/1900_weights/ 1900_weights/\n",
    "    \n",
    "    # Import the mLSTM babbler model\n",
    "    from unirep import babbler1900 as babbler\n",
    "    \n",
    "    # Where model weights are stored.\n",
    "    MODEL_WEIGHT_PATH = \"./1900_weights\"\n",
    "    \n",
    "else:\n",
    "    # Sync relevant weight files\n",
    "    !aws s3 sync --no-sign-request --quiet s3://unirep-public/64_weights/ 64_weights/\n",
    "    \n",
    "    # Import the mLSTM babbler model\n",
    "    from unirep import babbler64 as babbler\n",
    "    \n",
    "    # Where model weights are stored.\n",
    "    MODEL_WEIGHT_PATH = \"./64_weights\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "batch_size = 50\n",
    "b = babbler(batch_size=batch_size, model_path=MODEL_WEIGHT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Before you can train your model, \n",
    "sequences = []\n",
    "with open(\"emi_pos_seqs_0Y_1.txt\", \"r\") as source:\n",
    "    with open(\"formatted.txt\", \"w\") as destination:\n",
    "        for i,seq in enumerate(source):\n",
    "            seq = seq.strip()\n",
    "            sequences.append(seq)\n",
    "            if b.is_valid_seq(seq) and len(seq) < 275: \n",
    "                formatted = \",\".join(map(str,b.format_seq(seq)))\n",
    "                destination.write(formatted)\n",
    "                destination.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n",
      "rep\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-abae7d084eab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mnum1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnum1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mavg_hidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal_hidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal_cell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhs_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_rep_hs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequences\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0maverage_hidden_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mavg_hidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mfinal_hidden_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal_hidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "## \n",
    "average_hidden_list = []\n",
    "final_hidden_list = []\n",
    "hs_list = []\n",
    "final_cell_list = []\n",
    "\n",
    "\n",
    "num2 = range(0, 50)\n",
    "x = 0\n",
    "y = 50\n",
    "for i in num2:\n",
    "    num1 = range(x, y)\n",
    "    for j in num1:\n",
    "        avg_hidden, final_hidden, final_cell, hs_out = (b.get_rep_hs(sequences[j]))\n",
    "        average_hidden_list.append(avg_hidden)\n",
    "        final_hidden_list.append(final_hidden)\n",
    "        final_cell_list.append(final_cell)\n",
    "        hs_list.append(hs_out)\n",
    "        print('rep')\n",
    "    x = x + 50\n",
    "    y = y + 50\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             0         1         2         3         4         5         6   \\\n",
      "0     -0.165004  0.367741  0.358379 -0.652705  0.310745  0.112354  0.319343   \n",
      "1     -0.156224  0.020769 -0.005827 -0.946178 -0.175482  0.024309  0.109565   \n",
      "2     -0.076103  0.039707 -0.068597 -0.982010 -0.074966 -0.034950  0.068059   \n",
      "3     -0.058311  0.053986 -0.086645 -0.987298 -0.051170 -0.053258  0.027245   \n",
      "4     -0.003677  0.076352 -0.109282 -0.989626 -0.047260 -0.053738  0.027420   \n",
      "5     -0.038077  0.097799 -0.118403 -0.985669 -0.050498 -0.049629  0.037225   \n",
      "6      0.025612  0.064812 -0.113066 -0.984256 -0.059101 -0.051365  0.012105   \n",
      "7      0.049025  0.082313 -0.087995 -0.990922 -0.041432 -0.112213  0.029521   \n",
      "8      0.006583  0.135147 -0.078896 -0.990121 -0.015207 -0.122814  0.061241   \n",
      "9      0.008933  0.127565 -0.079991 -0.987132 -0.015113 -0.152265  0.025057   \n",
      "10     0.077980  0.103989 -0.058407 -0.984953 -0.021431 -0.128419  0.045190   \n",
      "11     0.026909  0.202782 -0.059125 -0.989396 -0.018550 -0.105592  0.042051   \n",
      "12     0.035936  0.159157 -0.088357 -0.969360 -0.026968 -0.056122  0.024937   \n",
      "13     0.059801  0.093132 -0.055557 -0.975596  0.002670 -0.008614  0.013640   \n",
      "14     0.062550  0.186707 -0.051769 -0.991475 -0.006423 -0.028718 -0.005721   \n",
      "15    -0.011214  0.167544 -0.043082 -0.991248 -0.011145 -0.035595  0.034426   \n",
      "16     0.058632  0.181080 -0.040065 -0.987976  0.017790 -0.069905  0.001385   \n",
      "17     0.029970  0.136943 -0.033349 -0.990374  0.005956 -0.082746  0.020479   \n",
      "18     0.000441  0.139913 -0.038506 -0.990033 -0.004634 -0.071803  0.016742   \n",
      "19     0.010915  0.160127 -0.046023 -0.979786 -0.002303 -0.025715 -0.015243   \n",
      "20     0.000773  0.222996 -0.049428 -0.987504  0.004572 -0.033628  0.006430   \n",
      "21     0.025222  0.186978 -0.068745 -0.972566  0.009812 -0.064642  0.029696   \n",
      "22     0.014874  0.136089 -0.071880 -0.985632 -0.014120 -0.041224 -0.008277   \n",
      "23     0.013732  0.130824 -0.094137 -0.940037  0.016129 -0.021758  0.006848   \n",
      "24     0.040988  0.195814 -0.055992 -0.972032  0.064121 -0.009580  0.047241   \n",
      "25     0.027895  0.113103 -0.053742 -0.974870  0.035050 -0.019315 -0.016683   \n",
      "26     0.006742  0.205769 -0.055555 -0.977195  0.057405 -0.013741  0.014226   \n",
      "27     0.018036  0.158473 -0.039804 -0.984140  0.025614 -0.047718 -0.009029   \n",
      "28     0.056865  0.188677 -0.014084 -0.986501  0.030536 -0.090299  0.052287   \n",
      "29    -0.006308  0.198464 -0.095512 -0.978152  0.017377 -0.077658  0.031064   \n",
      "...         ...       ...       ...       ...       ...       ...       ...   \n",
      "57970  0.046593  0.149810 -0.154968 -0.953573 -0.048792 -0.313150  0.044454   \n",
      "57971  0.059938  0.134720 -0.209616 -0.896642 -0.053993 -0.237574  0.037916   \n",
      "57972  0.031034  0.139372 -0.150573 -0.946660 -0.031573 -0.243918  0.068744   \n",
      "57973  0.061919  0.171347 -0.139751 -0.958641 -0.030036 -0.392742  0.163631   \n",
      "57974  0.061902  0.163673 -0.103726 -0.983134 -0.041401 -0.445384  0.142293   \n",
      "57975  0.076176  0.207993 -0.086464 -0.987241 -0.020677 -0.523809  0.108542   \n",
      "57976  0.022846  0.187957 -0.067655 -0.988135 -0.003385 -0.515963  0.078884   \n",
      "57977  0.058445  0.247894 -0.039653 -0.989159 -0.003874 -0.499575  0.066221   \n",
      "57978  0.038182  0.332430 -0.071995 -0.984957 -0.020299 -0.487089  0.077880   \n",
      "57979  0.047640  0.305601 -0.071624 -0.975879 -0.022298 -0.500462  0.073716   \n",
      "57980  0.020237  0.265196 -0.180402 -0.958944 -0.022173 -0.509084  0.062707   \n",
      "57981 -0.015664  0.206659 -0.171666 -0.957889 -0.004935 -0.455157  0.078339   \n",
      "57982 -0.009096  0.137998 -0.159842 -0.909108  0.002009 -0.410901  0.079197   \n",
      "57983  0.022663  0.138269 -0.225085 -0.874703  0.000176 -0.335096  0.077644   \n",
      "57984  0.027148  0.128867 -0.237998 -0.853466 -0.026455 -0.360919  0.118840   \n",
      "57985  0.029630  0.132166 -0.194634 -0.928840 -0.012251 -0.425091  0.066685   \n",
      "57986  0.035327  0.107461 -0.187161 -0.941899 -0.029110 -0.410643  0.025236   \n",
      "57987  0.045825  0.156524 -0.162761 -0.964773 -0.044554 -0.419005  0.122827   \n",
      "57988  0.050574  0.146446 -0.137626 -0.972193 -0.014800 -0.450098  0.157703   \n",
      "57989  0.042529  0.137518 -0.136263 -0.932718 -0.019228 -0.437788  0.097490   \n",
      "57990  0.011892  0.166522 -0.105141 -0.956214 -0.006292 -0.500911  0.109006   \n",
      "57991  0.065505  0.110037 -0.116282 -0.961485 -0.010817 -0.477115  0.075135   \n",
      "57992  0.028759  0.166004 -0.090662 -0.965018  0.006368 -0.531101  0.104527   \n",
      "57993  0.100840  0.201560 -0.078188 -0.986455 -0.003624 -0.628245  0.100810   \n",
      "57994  0.069854  0.224890 -0.077570 -0.992125 -0.012996 -0.614513  0.103349   \n",
      "57995  0.043673  0.255072 -0.131109 -0.986894 -0.017115 -0.531963  0.073211   \n",
      "57996  0.105789  0.307802 -0.023894 -0.981085 -0.008935 -0.548309  0.104028   \n",
      "57997 -0.015994  0.229767 -0.263450 -0.944393 -0.031041 -0.404078  0.081825   \n",
      "57998  0.078195  0.220669 -0.257574 -0.840847 -0.004622 -0.410609  0.107088   \n",
      "57999  0.060446  0.129597 -0.202520 -0.804595 -0.015652 -0.450982  0.101643   \n",
      "\n",
      "             7         8         9     ...           54        55        56  \\\n",
      "0      0.479474  0.566543  0.441343    ...     0.537194  0.512816  0.240133   \n",
      "1      0.108014  0.036832 -0.132778    ...     0.043055  0.063621 -0.021644   \n",
      "2      0.092981  0.163093 -0.054431    ...     0.037193  0.030412  0.071537   \n",
      "3      0.115106  0.120097 -0.164142    ...     0.046072  0.025641  0.055651   \n",
      "4      0.155599  0.163205 -0.143081    ...     0.053135  0.030944  0.110881   \n",
      "5      0.159635  0.174306 -0.124355    ...     0.062251  0.020353  0.117015   \n",
      "6      0.186465  0.157787 -0.161483    ...     0.067689  0.023296  0.123832   \n",
      "7      0.176079  0.200251 -0.158324    ...     0.054021  0.026638  0.132952   \n",
      "8      0.169030  0.212899 -0.221204    ...     0.060218  0.005316  0.015762   \n",
      "9      0.210119  0.217192 -0.265375    ...     0.067813  0.014017  0.088167   \n",
      "10     0.250093  0.124040 -0.227202    ...     0.056659 -0.003319  0.066461   \n",
      "11     0.147191  0.169260 -0.306931    ...     0.050413 -0.009246  0.021361   \n",
      "12     0.315876  0.157280 -0.265005    ...     0.095552 -0.015065  0.081112   \n",
      "13     0.342136  0.193036 -0.279929    ...     0.112255 -0.001664  0.103319   \n",
      "14     0.285693  0.127764 -0.365324    ...     0.137205 -0.009927  0.159071   \n",
      "15     0.264832  0.129591 -0.366905    ...     0.098436 -0.019926 -0.001309   \n",
      "16     0.367824  0.119783 -0.407532    ...     0.111354 -0.023082  0.160573   \n",
      "17     0.259494  0.185185 -0.361639    ...     0.065524 -0.013946  0.166405   \n",
      "18     0.197030  0.176720 -0.402051    ...     0.083203 -0.010517  0.140349   \n",
      "19     0.345719  0.141291 -0.340079    ...     0.137557 -0.016372  0.160160   \n",
      "20     0.172252  0.167280 -0.481209    ...     0.121422 -0.028451  0.109289   \n",
      "21     0.276378  0.180244 -0.314023    ...     0.123142 -0.016370  0.149385   \n",
      "22     0.157362  0.315546 -0.393191    ...     0.145586 -0.003677  0.190528   \n",
      "23     0.373720  0.179608 -0.306049    ...     0.224222 -0.006104  0.096121   \n",
      "24     0.325717  0.297871 -0.398989    ...     0.206409  0.015456  0.214602   \n",
      "25     0.264334  0.269589 -0.428428    ...     0.152294 -0.002339  0.173945   \n",
      "26     0.289775  0.301878 -0.507993    ...     0.158412 -0.073247  0.119530   \n",
      "27     0.285636  0.250421 -0.438021    ...     0.135970 -0.031341  0.082042   \n",
      "28     0.317975  0.223776 -0.359402    ...     0.092093 -0.033573  0.128310   \n",
      "29     0.134313  0.306728 -0.589696    ...     0.170220 -0.034644  0.065737   \n",
      "...         ...       ...       ...    ...          ...       ...       ...   \n",
      "57970  0.111229  0.345691 -0.415070    ...     0.098042  0.018392  0.039919   \n",
      "57971  0.188411  0.355420 -0.290871    ...     0.161899  0.020662  0.114232   \n",
      "57972  0.188584  0.443945 -0.319302    ...     0.083276  0.019023  0.102428   \n",
      "57973  0.220335  0.433223 -0.411445    ...     0.087502  0.018700  0.096845   \n",
      "57974  0.144694  0.433451 -0.445079    ...     0.056631  0.006658  0.037997   \n",
      "57975  0.139839  0.381155 -0.496806    ...     0.042492 -0.029395 -0.038524   \n",
      "57976  0.148233  0.411136 -0.465187    ...     0.040132 -0.029330 -0.058841   \n",
      "57977  0.145786  0.418334 -0.503318    ...     0.043360 -0.029286 -0.051510   \n",
      "57978  0.115848  0.485644 -0.462599    ...     0.069638 -0.022106 -0.044718   \n",
      "57979  0.122686  0.478947 -0.432691    ...     0.073913 -0.009685 -0.030016   \n",
      "57980  0.131306  0.482356 -0.355173    ...     0.123513 -0.000458  0.017913   \n",
      "57981  0.159289  0.429533 -0.311011    ...     0.087292  0.006094 -0.034585   \n",
      "57982  0.200346  0.409110 -0.286612    ...     0.134272  0.021488 -0.022607   \n",
      "57983  0.132445  0.411501 -0.295942    ...     0.177039  0.020691  0.045834   \n",
      "57984  0.186964  0.411661 -0.319017    ...     0.152108  0.024970  0.089159   \n",
      "57985  0.164091  0.436628 -0.405336    ...     0.108613  0.023507  0.051690   \n",
      "57986  0.129769  0.362844 -0.437854    ...     0.115532  0.016432  0.040133   \n",
      "57987  0.223139  0.422420 -0.384212    ...     0.086345  0.022911  0.112857   \n",
      "57988  0.169679  0.373908 -0.382872    ...     0.084456  0.016331  0.014615   \n",
      "57989  0.117962  0.361244 -0.471222    ...     0.124434 -0.005409 -0.084686   \n",
      "57990  0.225434  0.399747 -0.431698    ...     0.122824 -0.008634 -0.039353   \n",
      "57991  0.206152  0.349182 -0.428541    ...     0.111499  0.000590 -0.035384   \n",
      "57992  0.191042  0.428516 -0.512382    ...     0.108111 -0.026723 -0.059558   \n",
      "57993  0.218106  0.396436 -0.540441    ...     0.083798 -0.022601 -0.028265   \n",
      "57994  0.140850  0.419485 -0.544619    ...     0.064266 -0.049390 -0.039561   \n",
      "57995  0.122894  0.398120 -0.626252    ...     0.100581 -0.051600 -0.063085   \n",
      "57996  0.225822  0.379076 -0.330755    ...     0.064762 -0.014805 -0.032488   \n",
      "57997  0.071636  0.376656 -0.679033    ...     0.183447 -0.033089 -0.018848   \n",
      "57998  0.248376  0.374628 -0.278959    ...     0.188801  0.014494  0.027268   \n",
      "57999  0.135120  0.482137 -0.500786    ...     0.124239  0.018802  0.062215   \n",
      "\n",
      "             57        58        59        60        61        62        63  \n",
      "0      0.487939  0.511597  0.349602 -0.145424 -0.455004  0.441083  0.015762  \n",
      "1     -0.076822 -0.164030  0.893134  0.008492  0.016379  0.301379  0.005142  \n",
      "2     -0.032667 -0.108770  0.888038 -0.030944 -0.022160  0.497383 -0.016388  \n",
      "3     -0.030964 -0.047055  0.861368 -0.051400 -0.038630  0.666427 -0.020759  \n",
      "4     -0.036768 -0.044220  0.816845 -0.046780 -0.055321  0.660834 -0.026113  \n",
      "5     -0.064195 -0.058449  0.819727 -0.053925 -0.038737  0.674398 -0.017432  \n",
      "6     -0.048263 -0.037435  0.778645 -0.060062 -0.016980  0.652568 -0.019643  \n",
      "7     -0.030426 -0.038942  0.705063 -0.075229 -0.065626  0.657501 -0.067168  \n",
      "8      0.035158 -0.037259  0.774125 -0.105098 -0.029515  0.639903 -0.045360  \n",
      "9     -0.037739 -0.030386  0.660063 -0.127395 -0.085441  0.572246 -0.085825  \n",
      "10    -0.103659 -0.002936  0.692104 -0.162095 -0.067467  0.600933 -0.004912  \n",
      "11    -0.133821  0.000229  0.687867 -0.150174 -0.082718  0.557086 -0.009580  \n",
      "12    -0.200778 -0.011217  0.575031 -0.178972 -0.070315  0.479866 -0.006530  \n",
      "13    -0.151392  0.019952  0.523976 -0.228020 -0.025012  0.502675  0.033962  \n",
      "14    -0.185315  0.005921  0.560682 -0.257437 -0.066823  0.499618  0.007613  \n",
      "15    -0.078992 -0.023821  0.601956 -0.188844 -0.052808  0.455927 -0.025289  \n",
      "16    -0.142497  0.000680  0.599247 -0.224612 -0.105688  0.476499 -0.039322  \n",
      "17    -0.130926 -0.018574  0.462415 -0.183796 -0.049165  0.495711 -0.056372  \n",
      "18    -0.164547 -0.006038  0.537005 -0.174843 -0.052648  0.508777  0.009857  \n",
      "19    -0.267873 -0.016887  0.544652 -0.217414 -0.061035  0.447292  0.025399  \n",
      "20    -0.165588 -0.018657  0.525783 -0.214575 -0.087700  0.454747  0.008836  \n",
      "21    -0.232572 -0.008371  0.402627 -0.172029 -0.072603  0.491755 -0.008352  \n",
      "22    -0.105586 -0.042746  0.269446 -0.100759 -0.051021  0.420040 -0.000352  \n",
      "23    -0.236962 -0.018610  0.305138 -0.166258 -0.052423  0.425097  0.001632  \n",
      "24    -0.101726  0.002017  0.339098 -0.076670 -0.051397  0.542834 -0.036802  \n",
      "25    -0.183757 -0.035624  0.219369 -0.088381 -0.036086  0.476750 -0.031323  \n",
      "26    -0.001479 -0.051571  0.331985 -0.106514 -0.014167  0.477594  0.003510  \n",
      "27    -0.071645 -0.125622  0.219496 -0.098311 -0.047108  0.403606 -0.023932  \n",
      "28    -0.148694 -0.064050  0.278964 -0.128571 -0.075679  0.511326 -0.018728  \n",
      "29    -0.059973 -0.064885  0.340290 -0.142496 -0.040736  0.480546  0.002427  \n",
      "...         ...       ...       ...       ...       ...       ...       ...  \n",
      "57970 -0.039586  0.002735  0.225776 -0.193453 -0.071404  0.527312 -0.018689  \n",
      "57971 -0.035102 -0.015031  0.293901 -0.210864 -0.007010  0.510310  0.018827  \n",
      "57972  0.004952 -0.012272  0.240121 -0.209962  0.006711  0.475971 -0.023822  \n",
      "57973  0.006585  0.015490  0.193013 -0.213310 -0.023247  0.533602 -0.045954  \n",
      "57974  0.009146 -0.017611  0.194515 -0.204352  0.004184  0.524058  0.001370  \n",
      "57975 -0.029108 -0.017532  0.252752 -0.234761 -0.073874  0.581993 -0.020159  \n",
      "57976 -0.013300 -0.011446  0.258500 -0.233303 -0.074784  0.566367 -0.017404  \n",
      "57977  0.033064 -0.006424  0.351678 -0.236014 -0.096752  0.630267  0.004099  \n",
      "57978  0.119006 -0.030446  0.266432 -0.201272 -0.041106  0.633219 -0.016020  \n",
      "57979  0.114479 -0.026460  0.239311 -0.167056 -0.038887  0.697616 -0.020891  \n",
      "57980  0.071068 -0.026553  0.193796 -0.186819 -0.046434  0.659646 -0.022189  \n",
      "57981 -0.012164  0.009895  0.150958 -0.179413 -0.066468  0.644093 -0.056752  \n",
      "57982  0.042896 -0.007951  0.115643 -0.163574 -0.055035  0.509362 -0.069314  \n",
      "57983  0.056040 -0.010974  0.154317 -0.183302 -0.016678  0.527158 -0.040980  \n",
      "57984 -0.015913  0.004780  0.105649 -0.179631 -0.018421  0.527979 -0.055380  \n",
      "57985 -0.020595 -0.006571  0.132760 -0.173339 -0.043025  0.595972 -0.072412  \n",
      "57986 -0.022613 -0.008812  0.126030 -0.151145 -0.070611  0.556627 -0.029362  \n",
      "57987  0.021430  0.037006  0.174001 -0.161028 -0.028828  0.579042 -0.009882  \n",
      "57988 -0.013951  0.048644  0.206534 -0.163574 -0.038147  0.626119  0.032987  \n",
      "57989  0.051114 -0.038855  0.199659 -0.172327 -0.065799  0.539051 -0.004695  \n",
      "57990  0.065365 -0.043402  0.214284 -0.154807 -0.024203  0.581147 -0.010892  \n",
      "57991  0.029282 -0.026482  0.130757 -0.180148 -0.062305  0.508388 -0.029961  \n",
      "57992  0.065592 -0.037444  0.199556 -0.169978 -0.036799  0.595282 -0.038647  \n",
      "57993  0.055899 -0.007150  0.226691 -0.207733 -0.096215  0.633311 -0.036899  \n",
      "57994  0.051340 -0.005981  0.262089 -0.219056 -0.094307  0.632929 -0.043649  \n",
      "57995  0.108280 -0.019518  0.306590 -0.189577 -0.104374  0.610664 -0.029629  \n",
      "57996 -0.013681  0.006341  0.281123 -0.182167 -0.116198  0.663444 -0.056672  \n",
      "57997  0.115625 -0.008782  0.317144 -0.219940 -0.091974  0.603291 -0.032586  \n",
      "57998 -0.042439  0.021319  0.235724 -0.166095 -0.074820  0.663418 -0.067118  \n",
      "57999 -0.008990  0.000391  0.116626 -0.186481 -0.044190  0.630575 -0.089135  \n",
      "\n",
      "[58000 rows x 64 columns]\n"
     ]
    }
   ],
   "source": [
    "average_hidden_pd = pd.DataFrame(np.row_stack(average_hidden_list))\n",
    "final_hidden_pd = pd.DataFrame(np.row_stack(final_hidden_list))\n",
    "hidden_state = pd.DataFrame(np.row_stack(hs_list))\n",
    "print(hidden_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "average_hidden_pd.to_csv(\"emi_pos_reps_0Y_1.csv\")\n",
    "final_hidden_pd.to_csv(\"emi_pos_finalhidden_0Y_1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "save_loc = \"C:\\\\Users\\\\pkinn\\\\Documents\\\\UniRep\\\\full representations\\\\emi larger set\\\\\"\n",
    "data_name = 'emi_pos_reps_0Y_1'\n",
    "file_append = '.pickle'\n",
    "\n",
    "\n",
    "fn = save_loc + data_name + 'avg_hidden' + file_append\n",
    "with open(fn, 'wb') as f:\n",
    "    pickle.dump(average_hidden_list, f)\n",
    "\n",
    "fn = save_loc + data_name + 'final_hidden' + file_append\n",
    "with open(fn, 'wb') as f:\n",
    "    pickle.dump(final_hidden_list, f)\n",
    "\n",
    "fn = save_loc + data_name + 'final_cell' + file_append\n",
    "with open(fn, 'wb') as f:\n",
    "    pickle.dump(final_cell_list, f)\n",
    "   \n",
    "fn = save_loc + data_name + 'hidden_state' + file_append\n",
    "with open(fn, 'wb') as f:\n",
    "    pickle.dump(hs_list, f)\n",
    "   \n",
    "fn = save_loc + data_name + 'all_output_hs' + file_append\n",
    "with open(fn, 'wb') as f:\n",
    "    pickle.dump([average_hidden_list, final_hidden_list, final_cell_list, hs_list], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
